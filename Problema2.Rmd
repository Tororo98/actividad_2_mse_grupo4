---
title: "Actividad 2 MSE Problema 2"
author: "Sebastian Toro y Carlos Preciado"
date: "2025-09-25"
output:
  bookdown::html_document2:
    base_format: rmdformats::readthedown
    toc_depth: 3
    number_sections: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
```

## Descripci√≥n del Problema 2

El segundo problema se centra en el an√°lisis de los tiempos de espera de pacientes, un fen√≥meno que se modela con una distribuci√≥n Gamma. Los par√°metros de esta distribuci√≥n son $Œ±=3\;(forma)\quad y\;œÉ=2\;(escala)$, lo que implica una media poblacional te√≥rica (el par√°metro que deseamos estimar) de $Œº=Œ±\;œÉ=3√ó2=6\;minutos$.

Se han propuesto cuatro estimadores para esta media poblacional:

- $Œº_1:\;La\;media\;muestral$.

- $Œº_2:\;El\;punto\;medio\;del\;rango\;muestral$.

- $Œº_3:\;El\;valor\;m√≠nimo\;de\;la\;muestra$.

- $Œº_4:\;Una\;variaci√≥n\;de\;la\;media\;muestral\;(Media\;Escalada)$.

El objetivo de este an√°lisis es evaluar las propiedades de estos estimadores mediante simulaciones, determinando su **insesgadez, consistencia y eficiencia**. Estas propiedades son cruciales para seleccionar el estimador m√°s fiable en este caso y en el mundo real, ya que nos permiten cuantificar el error de muestreo y la robustez de nuestras inferencias.

## Simulaci√≥n y Distribuci√≥n de los Estimadores

```{r 2, echo=FALSE, fig.cap="Gr√°fico de Distribuciones Muestrales de los 4 Estimadores"}
knitr::include_graphics("graphs/distribucion_estimadores.png")
```

La Figura <a href="#fig:distribucion_estimadores">2</a> nos presenta la forma de la distribuci√≥n muestral de los cuatro estimadores, generadas a partir de 100 muestras de tama√±o $n=10$. La curva de densidad para cada estimador es la representaci√≥n visual de su comportamiento:

- $Œº_1$ **(Media muestral):** La curva de densidad de este estimador presenta una forma acampanada, con un pico claramente ubicado muy cerca de la l√≠nea de la media verdadera (6), es decir, con alta densidad alrededor del valor real de la media $(Œº=6)$. La simetr√≠a de su distribuci√≥n es un fuerte indicio visual de que podr√≠a ser un estimador **insesgado**.

- $Œº_2$ **(Punto Medio del Rango):** La curva de este estimador tambi√©n parece estar centrada alrededor de 6. Sin embargo, su pico es mucho menos pronunciado y la curva es notablemente m√°s ancha que la de $Œº_1$. Esto nos dice de inmediato que, aunque puede ser insesgado, es considerablemente **menos eficiente** debido a su mayor variabilidad.

- $Œº_3$ **(M√≠nimo de la Muestra):** Este es, con diferencia, el gr√°fico m√°s revelador. La curva de densidad de este estimador est√° completamente desplazada a la izquierda de la media verdadera. Su pico se encuentra alrededor de 1.8 y la distribuci√≥n est√° severamente sesgada a la derecha. Esto es la prueba visual definitiva de que es un estimador altamente sesgado, que sistem√°ticamente subestima el par√°metro real.

- $Œº_4$ **(Media Muestral Modificada):** La curva de densidad de este estimador es muy similar a la de Œº_1 en cuanto a su forma y dispersi√≥n, pero al observar la posici√≥n del pico, se encuentra ligeramente a la izquierda del 6. Este sutil desplazamiento visual es consistente con la teor√≠a de que este estimador tiene un peque√±o sesgo negativo, aunque su distribuci√≥n sigue siendo una aproximaci√≥n muy aceptable.

## Insesgadez

La **insesgadez** se cuantifica al comparar el promedio de las estimaciones con el valor verdadero del par√°metro. Con base en los resultados de nuestra simulaci√≥n (utilizando la semilla set.seed(123)), los promedios de cada estimador son:

```{r 3, echo=FALSE, fig.cap="Gr√°fico de Comparaci√≥n de Las Medias de los 100 Estimadores Simulados"}
knitr::include_graphics("graphs/insesgadez.png")
```

```{r, results='asis', echo = FALSE, message = FALSE, warning = FALSE}
library(ggplot2)
library(dplyr)
library(tidyr)
library(knitr)
library(kableExtra)

# Par√°metros de la distribuci√≥n Gamma
alpha <- 3
sigma <- 2
media_verdadera <- alpha * sigma

# N√∫mero de muestras y tama√±o de muestra
num_muestras_a <- 100
n_a <- 10

# Data frame para almacenar los resultados
resultados_a <- data.frame(
  Muestra = 1:num_muestras_a,
  mu_hat_1 = numeric(num_muestras_a),
  mu_hat_2 = numeric(num_muestras_a),
  mu_hat_3 = numeric(num_muestras_a),
  mu_hat_4 = numeric(num_muestras_a)
)

set.seed(123)
for (i in 1:num_muestras_a) {
  muestra <- rgamma(n_a, shape = alpha, scale = sigma)
  resultados_a$mu_hat_1[i] <- mean(muestra)
  resultados_a$mu_hat_2[i] <- (min(muestra) + max(muestra)) / 2
  resultados_a$mu_hat_3[i] <- min(muestra)
  resultados_a$mu_hat_4[i] <- sum(muestra) / (n_a + 1)
}

# Calcular medias de cada estimador
medias_estimadores <- resultados_a %>%
  summarise(across(starts_with("mu_hat"), ~ mean(.x))) %>%
  pivot_longer(
    cols = everything(),
    names_to = "Estimador",
    values_to = "Media_Estimada"
  )
medias_estimadores$Media_Verdadera <- media_verdadera

medias_estimadores %>%
  kable(caption = "Medias de los estimadores vs. media verdadera", digits = 3, format = "html") %>%
  kable_styling(full_width = FALSE, bootstrap_options = c("striped", "hover"))
```


La Figura <a href="#fig:insesgadez.png">3</a> compara la media de cada uno de los 100 estimadores simulados con la media verdadera de 6 minutos. Al observar el gr√°fico de comparaci√≥n, podemos detectar que los resultados num√©ricos y gr√°ficos confirman nuestra primera impresi√≥n:

- $Œº_1$: Para el estimador de media muestral, la media de las 100 estimaciones es 5.762. Presenta un sesgo negativo peque√±o, lo que lo convierte en un estimador bastante confiable y con buen comportamiento muestral.

- $Œº_2$: En el segundo estimador el Promedio = 6.669. Exhibe un sesgo positivo, sobreestimando el valor verdadero en aproximadamente +11%.

- $Œº_3$: En el tercer estimador el Promedio = 1.867, lo que representa un sesgo negativo sustancial. El valor m√≠nimo de la muestra es un estimador altamente sesgado, subestimando la media en m√°s de un 65%. Eso nos indicia que lo podemos decartar como estimador adecuado y no es apropiado para estimar la media.

- $Œº_4$: Finalmente, para la media escalada obtenemos que el Promedio = 5.238. Sesgado negativamente, como se predice por su construcci√≥n te√≥rica: $$\frac{n}{n+1}Œº$$ Lo que lo hace menos confiable que $Œº_1$.

Este an√°lisis nos demuestra que el sesgo no es una simple desviaci√≥n, sino un error sistem√°tico que no se corrige con el promedio de las muestras.

## Consistencia

La consistencia es la propiedad de un estimador cuya variabilidad disminuye a medida que el tama√±o de la muestra aumenta. Un estimador consistente se aproxima al par√°metro real a medida que n tiende a infinito.

```{r 4, echo=FALSE, fig.cap="Gr√°fico de Comparaci√≥n Variabilidad de Estimadores vs Tama√±o Muestral"}
knitr::include_graphics("graphs/consistencia.png")
```

La Figura <a href="#fig:consistencia.png">4</a> ilustra la varianza de cada estimador en funci√≥n del tama√±o de la muestra, desde $n=5$ hasta $n=1,000$. El gr√°fico revela una tendencia clara:

- Convergencia para todos menos para $Œº_2$: La varianza de los cuatro estimadores disminuye a medida que el tama√±o de la muestra aumenta. Esto nos permite concluir que estos 3 estimadores son consistentes para el par√°metro de la media, ya que la dispersi√≥n de sus distribuciones muestrales se reduce con m√°s datos.

- Diferencias en la velocidad de convergencia: La varianza de $Œº_3$ es la que cae de manera m√°s abrupta, seguida por las varianzas de $Œº_4$ y $Œº_1$ respectivamente y se mantienen en valores muy bajos a lo largo del eje x, sobre todo a partir de un tama√±o de muestra de aproximadamente 200 podemos ver que la varianza ya no presenta cambios tan dr√°sticos, mientras a su vez tiende a 0. Esto indica que es m√°s consistentes que los otros. La varianza de $Œº_2$ y, disminuye a un ritmo mucho m√°s lento y se mantiene en valores superiores, lo que lo hace menos fiable para tama√±os de muestra moderados. De hecho, podemos observar que su varianza deja de tender hacia 0 cuando la muestra alcanza un tama√±o de aproximandamente 125 y por el contrario se mantiene en valores entre 2.0 y 2.5

## Eficiencia

La eficiencia se relaciona con la varianza del estimador. Un estimador es m√°s eficiente si, para un mismo tama√±o de muestra, su distribuci√≥n muestral tiene la menor varianza posible.

```{r 5, echo=FALSE, fig.cap="Gr√°fico Varianza Muestral de los Estimadores"}
knitr::include_graphics("graphs/eficiencia_varianza.png")
```

```{r 6, echo=FALSE, fig.cap="Gr√°fico Coeficiente de Variaci√≥n de los Estimadores"}
knitr::include_graphics("graphs/eficiencia_cv.png")
```

Las Figuras <a href="#fig:eficiencia_varianza.png">5</a> y <a href="#fig:eficiencia_cv.png">6</a> comparan la varianza y el coeficiente de variaci√≥n de los estimadores para un tama√±o de muestra de n=10. Un an√°lisis de las estad√≠sticas pertinentes revela lo siguiente:

- $Œº_3$ tiene la varianza m√°s baja.
- $Œº_4$ y $Œº_1$ son los siguientes estimadores con las varianzas mas bajas y por debajo de 1. Espec√≠ficamente, 0.7513 y 0.9091 respectivamente.
- $Œº_2$ tiene por mucho, la varianza m√°s alta.

Ahora bien, con respecto a los coeficientes de variaci√≥n y gracias al gr√°fico <a href="#fig:eficiencia_cv.png">6</a> podemos concluir lo siguiente:

- El CV de $Œº_1$ y $Œº_4$ es notablemente bajo y practicamente igual.
- El CV de $Œº_2$ es mayor, y esto nos podr√≠a indicar una mayor dispersi√≥n relativa.
- El CV de $Œº_3$ es extremadamente alto, confirmando que es un estimador muy poco fiable, incluso aunque su varianza sea la m√°s baja en el anterior gr√°fico.

Tras el an√°lisis de las simulaciones y la interpretaci√≥n de los gr√°ficos, las propiedades de los estimadores se clarifican de forma definitiva. Al considerar el comportamiento de cada estimador con respecto a la insesgadez, la consistencia y la eficiencia, podemos establecer un ranking de fiabilidad.

- *El Estimador Menos Sesgado:* $Œº_1$ pues con un promedio de 5.762, es el estimador con el menor sesgo. Aunque no es perfectamente insesgado en esta simulaci√≥n espec√≠fica (debido al error de muestreo), su desviaci√≥n del valor verdadero de 6 es m√≠nima. En contraste, $Œº_2$ sobreestima, y $Œº_3$ y $Œº_4$ subestiman de manera significativa. La baja variabilidad de $Œº_1$ y $Œº_4$ los hace altamente consistentes, pero la ausencia de sesgo en lo $Œº_1$ posiciona como el m√°s fiable en este aspecto. Recordemos ademas que como pudimos observar, los estimadores con media muestral mas cercana al par√°metro poblacional fueron $Œº_1$ y $Œº_4$, por lo tanto ser√≠a l√≥gico hacer una comparaci√≥n por pares, agrupando estos dos, llegando a la misma conclusi√≥n de que $Œº_1$ es el estimador m√°s fiable entre los dos.

- *El Estimador M√°s Eficiente:* Inicialmente uno podr√≠a pensar que $Œº_3$ ocupar√≠a este lugar puesto que presenta la varianza m√°s baja (0.7513), lo que te√≥ricamente lo har√≠a el m√°s eficiente. Sin embargo, en el mismo an√°lisis, nos podemos dar cuenta que esta es enga√±osamente baja porque sus valores est√°n fuertemente concentrados en una regi√≥n alejada de la media poblacional, lo que confirma el sesgo. La varianza mide la dispersi√≥n alrededor de su propia media (1.867), no alrededor del par√°metro que se quiere estimar (6). Debido a esto y por comparaci√≥n el estimador m√°s eficiente es $Œº_1$ con una varianza de 0.9091. Esto debido a que aunque $Œº_4$ tiene una varianza de 0.7513, es el resultado de un sesgo sustancial, es decir, la *media del estimador est√° lejos del valor verdadero*. Algo que incluso podemos comprobar al calcular el MSE que nos da un valor de 17.83 al seguir la formula:

$$
MSE(\hat{\theta}) = Var(\hat{\theta}) + (Sesgo(\hat{\theta}))^2
$$
En la pr√°ctica, un estimador con una varianza baja pero un sesgo alto es in√∫til para inferir sobre la media poblacional. La eficiencia de $Œº_1$ es la mejor entre los estimadores que se centran en el valor correcto.

- *El estimador M√°s Consistente:* De igual manera, viendo el gr√°fico de variabilidad de los estimadores vs el tama√±o muestral, podr√≠amos pensar que $Œº_3$ ocupa este lugar debido a que su linea 
es la que "cae de manera m√°s abrupta". Esto se debe a su naturaleza: el valor m√≠nimo tiende a estabilizarse r√°pidamente a medida que el tama√±o de la muestra aumenta. Esto lo convierte en el estimador con la convergencia m√°s r√°pida hacia su propio valor esperado, lo que es un tipo de consistencia, aunque in√∫til para la estimaci√≥n del par√°metro que nos interesa. En t√©rminos pr√°cticos, la consistencia de los estimadores sin sesgo es lo que importa. En ese sentido, $Œº_1$ y $Œº_4$ son los 
estimadores que m√°s nos interesan, ya que su varianza tiende a 0 a medida que se acercan al valor verdadero justo despu√©s de $Œº_3$, como lo podemos evidenciar en el gr√°fico <a href="#fig:consistencia.png">4</a> que muestra como sus varianzas tienden hacia 0 con una diferencia con $Œº_3$ pr√°cticamente imperceptible gr√°ficamente 


## Referencias

- Casella, G., & Berger, R. L. (2002). *Statistical Inference* (2nd ed.). Duxbury.  
- Wasserman, L. (2004). *All of Statistics: A Concise Course in Statistical Inference*. Springer.  
- Rice, J. A. (2007). *Mathematical Statistics and Data Analysis* (3rd ed.). Cengage.  
- Ross, S. (2019). *Introduction to Probability and Statistics for Engineers and Scientists* (6th ed.). Academic Press.  
- Montgomery, D. C., & Runger, G. C. (2018). *Applied Statistics and Probability for Engineers* (7th ed.). Wiley.  
- Agresti, A., & Franklin, C. (2017). *Statistics: The Art and Science of Learning from Data* (4th ed.). Pearson.  
- DeGroot, M. H., & Schervish, M. J. (2012). *Probability and Statistics* (4th ed.). Addison-Wesley.  
- Blitzstein, J. K., & Hwang, J. (2019). *Introduction to Probability*. Chapman & Hall/CRC.  
- Downey, A. (2012). *Think Stats: Exploratory Data Analysis in Python*. O‚ÄôReilly. (Disponible gratis en l√≠nea).  
- James, G., Witten, D., Hastie, T., & Tibshirani, R. (2021). *An Introduction to Statistical Learning with Applications in R* (2nd ed.). Springer.  
  üëâ [https://www.statlearning.com](https://www.statlearning.com)  
- OpenIntro. (2021). *OpenIntro Statistics* (4th ed.). OpenIntro Project.  
  üëâ [https://www.openintro.org/book/os/](https://www.openintro.org/book/os/)